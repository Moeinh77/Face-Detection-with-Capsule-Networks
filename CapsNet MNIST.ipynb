{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CapsNet MNIST\n",
    "\n",
    "This is an implementation of Geoffrey Hinton's CapsNet architecture as described in [Sabour 2017]. The implementation is (very) insipired by Aurélien Géron's implementation and is for learning purposes only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import layers\n",
    "import losses\n",
    "\n",
    "from data import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup TensorBoard logdir\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ROOT_LOGDIR = \"tf_logs\"\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "logdir = \"{}/run-{}\".format(ROOT_LOGDIR, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stabilize ouptut accross runs\n",
    "# TODO give the caller more control over what to reset\n",
    "\n",
    "def reset(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    np.random.seed(seed)\n",
    "    tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_val, y_val), (X_test, y_test)= mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_elem = X_train.max()\n",
    "min_elem = X_train.min()\n",
    "\n",
    "X_train = (X_train - min_elem)/(max_elem - min_elem)\n",
    "X_val = (X_val - min_elem)/(max_elem - min_elem)\n",
    "X_test = (X_test - min_elem)/(max_elem - min_elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def peek_data(n_samples=5):\n",
    "    plt.figure(figsize=(n_samples * 2, 3))\n",
    "    \n",
    "    for index in range(n_samples):\n",
    "        plt.subplot(1, n_samples, index + 1)\n",
    "        \n",
    "        # images are stored as flattened numpy arrays\n",
    "        sample_image = X_train[index].reshape(28, 28)\n",
    "        \n",
    "        plt.imshow(sample_image, cmap=\"binary\")\n",
    "        plt.axis(\"off\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def peek_labels(n_samples=5):\n",
    "    print(y_train[:n_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "peek_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 3 4 6 1]\n"
     ]
    }
   ],
   "source": [
    "peek_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CapsNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Inputs\n",
    "\n",
    "X = tf.placeholder(shape=[None, 28, 28, 1], dtype=tf.float32, name=\"X\")\n",
    "y = tf.placeholder(shape=[None], dtype=tf.int64, name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Model\n",
    "\n",
    "conv1 = tf.layers.conv2d(\n",
    "    X, \n",
    "    filters=256,\n",
    "    kernel_size=9,\n",
    "    strides=1,\n",
    "    padding=\"valid\",\n",
    "    name=\"conv1\"\n",
    ")\n",
    "\n",
    "primaryCaps = layers.convCaps(\n",
    "    conv1, \n",
    "    filters=32, \n",
    "    dimensions=8,\n",
    "    kernel_size=9,\n",
    "    strides=2,\n",
    "    activation=tf.nn.relu,\n",
    "    name=\"primaryCaps\"\n",
    ")\n",
    "\n",
    "digitCaps = layers.denseCaps(\n",
    "    primaryCaps, \n",
    "    capsules=10, \n",
    "    dimensions=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Predictions\n",
    "\n",
    "# The probability that a given digit is present is encoded by the length of the corresponding digit capsule\n",
    "probabilities = layers.norm(digitCaps, axis=-1, name=\"probabilities\")\n",
    "\n",
    "with tf.variable_scope(\"predictions\"):\n",
    "    predictions = tf.argmax(probabilities, axis=-1, name=\"predictions\")\n",
    "\n",
    "# Classification accuracy on the sample batch\n",
    "with tf.variable_scope(\"accuracy\"):\n",
    "    correct = tf.equal(y, predictions, name=\"correct\")\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Reconstructions\n",
    "\n",
    "with tf.variable_scope(\"reconstructions\"):\n",
    "    mask_with_labels = tf.placeholder_with_default(False, shape=(), name=\"mask_with_labels\")\n",
    "\n",
    "    reconstruction_targets = tf.cond(mask_with_labels,\n",
    "                                     lambda: y,\n",
    "                                     lambda: predictions,\n",
    "                                     name=\"reconstruction_targets\")\n",
    "\n",
    "    reconstructions = layers.denseDecoder(digitCaps, reconstruction_targets, [512, 1024, 28*28], name=\"reconstructions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Loss\n",
    "with tf.name_scope(\"loss\"):\n",
    "\n",
    "    with tf.variable_scope(\"margin_loss\"):\n",
    "        y_one_hot = tf.one_hot(y, depth=10, name=\"y_one_hot\")\n",
    "        margin_loss = losses.margin_loss(y_one_hot, probabilities, name=\"loss\")\n",
    "\n",
    "    reconstruction_loss = losses.reconstruction_loss(X, reconstructions, name=\"reconstruction_loss\")\n",
    "\n",
    "    alpha = tf.constant(0.0005, name=\"alpha\")\n",
    "    loss = margin_loss + alpha * reconstruction_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_summary = tf.summary.scalar('accuracy', accuracy)\n",
    "margin_loss_summary = tf.summary.scalar('margin_loss', margin_loss)\n",
    "reconstruction_loss_summary = tf.summary.scalar('reconstruction_loss', reconstruction_loss)\n",
    "loss_summary = tf.summary.scalar('loss', loss)\n",
    "summaries = tf.summary.merge_all()\n",
    "\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Val accuracy: 100.0000% Loss: 0.003929 (improved)\n",
      "Epoch: 2 Val accuracy: 100.0000% Loss: 0.104491\n",
      "Epoch: 3 Val accuracy: 100.0000% Loss: 0.000150 (improved)\n",
      "Epoch: 4 Val accuracy: 100.0000% Loss: 0.004459\n",
      "Epoch: 5 Val accuracy: 100.0000% Loss: 0.000647\n",
      "Epoch: 6 Val accuracy: 100.0000% Loss: 0.022375\n",
      "Epoch: 7 Val accuracy: 100.0000% Loss: 0.099671\n",
      "Epoch: 8 Val accuracy: 100.0000% Loss: 0.003710\n",
      "Epoch: 9 Val accuracy: 100.0000% Loss: 0.002642\n",
      "Epoch: 10 Val accuracy: 100.0000% Loss: 0.016479\n",
      "Epoch: 11 Val accuracy: 100.0000% Loss: 0.001302\n",
      "Epoch: 12 Val accuracy: 100.0000% Loss: 0.000165\n",
      "Epoch: 13 Val accuracy: 100.0000% Loss: 0.000152\n",
      "Epoch: 14 Val accuracy: 100.0000% Loss: 0.000209\n",
      "Epoch: 15 Val accuracy: 100.0000% Loss: 0.000876\n",
      "Epoch: 16 Val accuracy: 100.0000% Loss: 0.000609\n",
      "Epoch: 17 Val accuracy: 100.0000% Loss: 0.000399\n",
      "Epoch: 18 Val accuracy: 100.0000% Loss: 0.000109 (improved)\n",
      "Epoch: 19 Val accuracy: 100.0000% Loss: 0.000109 (improved)\n",
      "Epoch: 20 Val accuracy: 100.0000% Loss: 0.000108 (improved)\n",
      "Epoch: 21 Val accuracy: 100.0000% Loss: 0.000108 (improved)\n",
      "Epoch: 22 Val accuracy: 100.0000% Loss: 0.000295\n",
      "Epoch: 23 Val accuracy: 100.0000% Loss: 0.001033\n",
      "Epoch: 24 Val accuracy: 100.0000% Loss: 0.001214\n",
      "Epoch: 25 Val accuracy: 100.0000% Loss: 0.000102 (improved)\n",
      "Epoch: 26 Val accuracy: 100.0000% Loss: 0.000101 (improved)\n",
      "Epoch: 27 Val accuracy: 100.0000% Loss: 0.000099 (improved)\n",
      "Epoch: 28 Val accuracy: 100.0000% Loss: 0.000167\n",
      "Epoch: 29 Val accuracy: 100.0000% Loss: 0.001698\n",
      "Epoch: 30 Val accuracy: 100.0000% Loss: 0.000094 (improved)\n",
      "Epoch: 31 Val accuracy: 100.0000% Loss: 0.000093 (improved)\n",
      "Epoch: 32 Val accuracy: 100.0000% Loss: 0.000091 (improved)\n",
      "Epoch: 33 Val accuracy: 100.0000% Loss: 0.000089 (improved)\n",
      "Epoch: 34 Val accuracy: 100.0000% Loss: 0.000087 (improved)\n",
      "Epoch: 35 Val accuracy: 100.0000% Loss: 0.000084 (improved)\n",
      "Epoch: 36 Val accuracy: 100.0000% Loss: 0.000081 (improved)\n",
      "Epoch: 37 Val accuracy: 100.0000% Loss: 0.000102\n",
      "Epoch: 38 Val accuracy: 100.0000% Loss: 0.000075 (improved)\n",
      "Epoch: 39 Val accuracy: 100.0000% Loss: 0.000069 (improved)\n",
      "Iteration: 1/1 (100.0%)  Loss: 0.00007"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-2b93477b1816>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m                 feed_dict={\n\u001b[1;32m     61\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                     \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m                 }\n\u001b[1;32m     64\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "training_op  = optimizer.minimize(loss, name=\"training_op\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 1\n",
    "checkpoint_path = \"./capsnet_save\"\n",
    "\n",
    "X_train = X_train[:5]\n",
    "y_train = y_train[:5]\n",
    "\n",
    "X_val = X_train[:5]\n",
    "y_val =y_train[:5]\n",
    "\n",
    "n_iterations_per_epoch = len(X_train) // batch_size\n",
    "n_iterations_validation = len(X_val) // batch_size\n",
    "\n",
    "best_loss_val = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize the graph\n",
    "    init.run()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(n_iterations_per_epoch):\n",
    "            X_batch, y_batch = X_train[iteration:iteration+batch_size+1], y_train[iteration:iteration+batch_size+1]\n",
    "            \n",
    "            _, loss_train = sess.run(\n",
    "                [training_op, loss],\n",
    "                feed_dict={\n",
    "                    X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                    y: y_batch.reshape([-1]),\n",
    "                    mask_with_labels: True\n",
    "                })\n",
    "        \n",
    "            print(\n",
    "                \"\\rIteration: {}/{} ({:.1f}%)  Loss: {:.5f}\".format(\n",
    "                    iteration + 1, \n",
    "                    n_iterations_per_epoch, \n",
    "                    (iteration + 1)/n_iterations_per_epoch * 100, \n",
    "                    loss_train\n",
    "                ),\n",
    "                end=\"\"\n",
    "            )\n",
    "        \n",
    "        # Measure validation loss and accuracy at the end of each epoch:\n",
    "        loss_vals = []\n",
    "        acc_vals = []\n",
    "        \n",
    "        for iteration in range(n_iterations_validation):\n",
    "            X_batch, y_batch = X_val[iteration:iteration+batch_size+1], y_val[iteration:iteration+batch_size+1]\n",
    "            \n",
    "            loss_val, acc_val = sess.run(\n",
    "                [loss, accuracy],\n",
    "                feed_dict={\n",
    "                    X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                    y: y_batch.reshape([-1]),\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            loss_vals.append(loss_val)\n",
    "            acc_vals.append(acc_val)\n",
    "            \n",
    "            print(\n",
    "                \"\\rEvaluating the model: {}/{} ({:.1f})%\".format(\n",
    "                    iteration + 1,\n",
    "                    n_iterations_validation,\n",
    "                    (iteration + 1) * 100 / n_iterations_validation\n",
    "                ),\n",
    "                end=\" \" * 10\n",
    "            )\n",
    "            \n",
    "            # Log in TensorBoard\n",
    "            if iteration % 10 == 0:\n",
    "                summary_str = summaries.eval(\n",
    "                    feed_dict={\n",
    "                        X: X_batch.reshape([-1, 28, 28, 1]), \n",
    "                        y: y_batch.reshape([-1])\n",
    "                    }\n",
    "                )\n",
    "                file_writer.add_summary(summary_str, epoch * n_iterations_validation + iteration)\n",
    "            \n",
    "        loss_val = np.mean(loss_vals)\n",
    "        acc_val = np.mean(acc_vals)\n",
    "        \n",
    "        print(\n",
    "            \"\\rEpoch: {} Val accuracy: {:.4f}% Loss: {:.6f}{}\".format(\n",
    "                epoch + 1,\n",
    "                acc_val * 100,\n",
    "                loss_val,\n",
    "                \" (improved)\" if loss_val < best_loss_val else \"\"\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Save the model if it improved:\n",
    "        if loss_val < best_loss_val:\n",
    "            save_path = saver.save(sess, checkpoint_path)\n",
    "            best_loss_val = loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./capsnet_save\n",
      "Final test accuracy: 7.8125% Loss: 0.747725 \n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "\n",
    "n_iterations_test = len(X_test) // batch_size\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    \n",
    "    loss_tests = []\n",
    "    acc_tests = []\n",
    "    \n",
    "    for iteration in range(n_iterations_test):\n",
    "        X_batch, y_batch = X_test[iteration:iteration+batch_size+1], y_test[iteration:iteration+batch_size+1]\n",
    "        \n",
    "        loss_test, acc_test = sess.run(\n",
    "            [loss, accuracy],\n",
    "            feed_dict={\n",
    "                X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                y: y_batch.reshape([-1]),\n",
    "            },\n",
    "        )\n",
    "        \n",
    "        loss_tests.append(loss_test)\n",
    "        acc_tests.append(acc_test)\n",
    "        \n",
    "        print(\n",
    "            \"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
    "                iteration + 1,\n",
    "                n_iterations_test,\n",
    "                (iteration + 1) * 100 / n_iterations_test\n",
    "            ),\n",
    "            end=\" \" * 10\n",
    "        )\n",
    "        \n",
    "    loss_test = np.mean(loss_tests)\n",
    "    acc_test = np.mean(acc_tests)\n",
    "    \n",
    "    print(\"\\rFinal test accuracy: {:.4f}% Loss: {:.6f}\".format(acc_test * 100, loss_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./capsnet_save\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "\n",
    "n_samples = 2\n",
    "\n",
    "sample_images = X_train[:n_samples].reshape([-1, 28, 28, 1])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    digitCaps_output_value, reconstructions_value, predictions_value = sess.run(\n",
    "        [digitCaps, reconstructions, predictions],\n",
    "        feed_dict={\n",
    "            X: sample_images,\n",
    "            y: np.array([], dtype=np.int64) # as explained earlier, this will not be used\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x216 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x216 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_images = sample_images.reshape([-1, 28, 28])\n",
    "reconstructions_value = reconstructions_value.reshape([-1, 28, 28])\n",
    "\n",
    "plt.figure(figsize=(n_samples * 2, 3))\n",
    "for index in range(n_samples):\n",
    "    plt.subplot(1, n_samples, index + 1)\n",
    "    plt.imshow(sample_images[index], cmap=\"binary\")\n",
    "    plt.title(\"Label:\" + str(y_test[index]))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(n_samples * 2, 3))\n",
    "for index in range(n_samples):\n",
    "    plt.subplot(1, n_samples, index + 1)\n",
    "    plt.imshow(reconstructions_value[index], cmap=\"binary\")\n",
    "    plt.title(\"Predicted:\" + str(predictions_value[index]))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bachelor-Thesis",
   "language": "python",
   "name": "bachelor-thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

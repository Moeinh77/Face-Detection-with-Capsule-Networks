{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CapsNet MNIST\n",
    "\n",
    "This is an implementation of Geoffrey Hinton's CapsNet architecture as described in [Sabour 2017]. The implementation is (very) insipired by Aurélien Géron's implementation and is for learning purposes only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import layers\n",
    "import losses\n",
    "from utils import batch, norm\n",
    "from data import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard logging\n",
    "ROOT_LOGDIR = \"tf_logs\"\n",
    "\n",
    "def log_run():\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "    logdir = \"{}/run-{}\".format(ROOT_LOGDIR, now)\n",
    "    \n",
    "    return logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stabilize ouptut accross runs\n",
    "# TODO give the caller more control over what to reset\n",
    "\n",
    "def reset(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    np.random.seed(seed)\n",
    "    tf.set_random_seed(42)\n",
    "    \n",
    "reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_val, y_val), (X_test, y_test)= mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_elem = X_train.max()\n",
    "min_elem = X_train.min()\n",
    "\n",
    "X_train = (X_train - min_elem)/(max_elem - min_elem)\n",
    "X_val = (X_val - min_elem)/(max_elem - min_elem)\n",
    "X_test = (X_test - min_elem)/(max_elem - min_elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peek_data(n_samples=5):\n",
    "    plt.figure(figsize=(n_samples * 2, 3))\n",
    "    \n",
    "    for index in range(n_samples):\n",
    "        plt.subplot(1, n_samples, index + 1)\n",
    "        \n",
    "        # images are stored as flattened numpy arrays\n",
    "        sample_image = X_train[index].reshape(28, 28)\n",
    "        \n",
    "        plt.imshow(sample_image, cmap=\"binary\")\n",
    "        plt.axis(\"off\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def peek_labels(n_samples=5):\n",
    "    print(y_train[:n_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "peek_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 3 4 6 1]\n"
     ]
    }
   ],
   "source": [
    "peek_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CapsNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "## Inputs\n",
    "\n",
    "X = tf.placeholder(shape=[None, 28, 28, 1], dtype=tf.float32, name=\"X\")\n",
    "y = tf.placeholder(shape=[None], dtype=tf.int64, name=\"y\")\n",
    "y_one_hot = tf.one_hot(y, depth=10, name=\"y_one_hot\")\n",
    "## Model\n",
    "\n",
    "conv1 = tf.layers.conv2d(\n",
    "    X, \n",
    "    filters=256,\n",
    "    kernel_size=9,\n",
    "    strides=1,\n",
    "    padding=\"valid\",\n",
    "    name=\"conv1\"\n",
    ")\n",
    "\n",
    "primaryCaps = layers.primaryCaps(\n",
    "    conv1, \n",
    "    caps=32, \n",
    "    dims=8,\n",
    "    kernel_size=9,\n",
    "    strides=2,\n",
    "    name=\"primaryCaps\"\n",
    ")\n",
    "\n",
    "digitCaps = layers.denseCaps(\n",
    "    primaryCaps, \n",
    "    caps=10, \n",
    "    dims=16\n",
    ")\n",
    "\n",
    "\n",
    "probabilities = norm(digitCaps, axis=-1, name=\"probabilities\")\n",
    "margin_loss = losses.margin_loss(y_one_hot, probabilities, name=\"margin_loss\")\n",
    "\n",
    "\n",
    "predictions = tf.argmax(probabilities, axis=-1, name=\"predictions\")\n",
    "with tf.variable_scope(\"accuracy\"):\n",
    "    correct = tf.equal(y, predictions, name=\"correct\")\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "    \n",
    "\n",
    "with tf.variable_scope(\"reconstructions\"):\n",
    "    mask_with_labels = tf.placeholder_with_default(False, shape=(), name=\"mask_with_labels\")\n",
    "\n",
    "    reconstruction_targets = tf.cond(mask_with_labels,\n",
    "                                     lambda: y,\n",
    "                                     lambda: predictions,\n",
    "                                     name=\"reconstruction_targets\")\n",
    "\n",
    "    reconstructions = layers.denseDecoder(digitCaps, reconstruction_targets, [512, 1024, 28*28], name=\"reconstructions\")\n",
    "    \n",
    "reconstruction_loss = losses.reconstruction_loss(X, reconstructions, name='reconstruction_loss')\n",
    "\n",
    "alpha = tf.constant(0.0005, name='alpha')\n",
    "loss = margin_loss + alpha * reconstruction_loss\n",
    "\n",
    "train_margin_loss_summary = tf.summary.scalar('train_margin_loss', margin_loss)\n",
    "train_reconstruction_loss_summary = tf.summary.scalar('train_reconstruction_loss', reconstruction_loss)\n",
    "train_loss_summrary = tf.summary.scalar('train_loss', loss)\n",
    "train_accuracy = tf.summary.scalar('train_accuracy', accuracy)\n",
    "train_summaries = tf.summary.merge(\n",
    "    [train_margin_loss_summary, train_reconstruction_loss_summary, train_loss_summrary, train_accuracy]\n",
    ")\n",
    "\n",
    "val_margin_loss_summary = tf.summary.scalar('val_margin_loss', margin_loss)\n",
    "val_reconstruction_loss_summary = tf.summary.scalar('val_reconstruction_loss', reconstruction_loss)\n",
    "val_loss_summrary = tf.summary.scalar('val_loss', loss)\n",
    "val_accuracy = tf.summary.scalar('val_accuracy', accuracy)\n",
    "val_summaries = tf.summary.merge(\n",
    "    [val_margin_loss_summary, val_reconstruction_loss_summary, val_loss_summrary, val_accuracy]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/2]\n",
      "Train | Average Accuracy: 97.2949% Loss: 0.042551                              \n",
      "Validation | Iteration 205/208 (98.6%) | Batch Accuracy: 100.0000% Loss: 0.028537HERE\n",
      "Validation | Average Accuracy: 97.0295% Loss: 0.042334                              \n",
      "[Epoch 2/2]\n",
      "Train | Average Accuracy: 98.3766% Loss: 0.026235                              \n",
      "Validation | Iteration 205/208 (98.6%) | Batch Accuracy: 100.0000% Loss: 0.025990HERE\n",
      "Validation | Average Accuracy: 97.2687% Loss: 0.039177                              \n"
     ]
    }
   ],
   "source": [
    "logdir = log_run()\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "train_op  = optimizer.minimize(loss, name=\"training_op\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "num_epochs = 2\n",
    "batch_size = 24\n",
    "checkpoint_path = \"./capsnet_mnist_save\"\n",
    "\n",
    "\n",
    "train_iterations_per_epoch = len(X_train) // batch_size\n",
    "val_iterations_per_epoch = len(X_val) // batch_size\n",
    "\n",
    "best_val_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('[Epoch {}/{}]'.format(epoch + 1, num_epochs))\n",
    "        \n",
    "        # TRAIN\n",
    "        train_losses = []\n",
    "        train_accuracies = []\n",
    "        \n",
    "        for iteration, (X_batch, y_batch) in enumerate(batch(X_train, y_train, batch_size=batch_size)):\n",
    "            \n",
    "            train_op.run(\n",
    "                feed_dict={\n",
    "                    X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                    y: y_batch.reshape([-1]),\n",
    "                    mask_with_labels: True\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            train_loss, train_accuracy = sess.run(\n",
    "                [loss, accuracy],\n",
    "                feed_dict={\n",
    "                    X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                    y: y_batch.reshape([-1]),\n",
    "                    mask_with_labels: True\n",
    "                }\n",
    "            )\n",
    "        \n",
    "            train_losses.append(train_loss)\n",
    "            train_accuracies.append(train_accuracy)\n",
    "        \n",
    "            if (iteration + 1) % 10 == 0:\n",
    "                print('\\rTrain | Iteration {}/{} ({:.1f}%) | Batch Accuracy: {:.4f}% Loss: {:.6f}'.format(\n",
    "                    iteration + 1,\n",
    "                    train_iterations_per_epoch,\n",
    "                    (iteration + 1) * 100 / train_iterations_per_epoch,\n",
    "                    train_accuracy * 100,\n",
    "                    train_loss\n",
    "                ), \n",
    "                end=\"\")\n",
    "                \n",
    "                train_summary_str = train_summaries.eval(\n",
    "                    feed_dict={\n",
    "                        X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                        y: y_batch.reshape([-1])\n",
    "                    }\n",
    "                )\n",
    "                \n",
    "                file_writer.add_summary(train_summary_str, epoch * train_iterations_per_epoch + iteration)\n",
    "            \n",
    "        avg_train_loss = np.mean(train_losses)\n",
    "        avg_train_accuracy = np.mean(train_accuracies)\n",
    "        \n",
    "        print('\\rTrain | Average Accuracy: {:.4f}% Loss: {:.6f}'.format(\n",
    "            avg_train_accuracy * 100,\n",
    "            avg_train_loss), \n",
    "        end=\" \" * 30 + \"\\n\")\n",
    "                \n",
    "        \n",
    "        # VALIDATE\n",
    "        val_losses = []\n",
    "        val_accuracies = []\n",
    "        \n",
    "        for iteration, (X_batch, y_batch) in enumerate(batch(X_val, y_val, batch_size=batch_size)):\n",
    "            \n",
    "            val_loss, val_accuracy = sess.run(\n",
    "                [loss, accuracy],\n",
    "                feed_dict={\n",
    "                    X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                    y: y_batch.reshape([-1]),\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            val_losses.append(val_loss)\n",
    "            val_accuracies.append(val_accuracy)\n",
    "            \n",
    "            if (iteration + 1) % 5 == 0:\n",
    "                print('\\rValidation | Iteration {}/{} ({:.1f}%) | Batch Accuracy: {:.4f}% Loss: {:.6f}'.format(\n",
    "                    iteration + 1,\n",
    "                    val_iterations_per_epoch,\n",
    "                    (iteration + 1) * 100 / val_iterations_per_epoch,\n",
    "                    val_accuracy * 100,\n",
    "                    val_loss\n",
    "                ), \n",
    "                end=\"\")\n",
    "            \n",
    "         \n",
    "                val_summary_str = val_summaries.eval(\n",
    "                    feed_dict={\n",
    "                        X: X_batch.reshape([-1, 28, 28, 1]), \n",
    "                        y: y_batch.reshape([-1])\n",
    "                    }\n",
    "                )\n",
    "                file_writer.add_summary(val_summary_str, epoch * val_iterations_per_epoch + iteration)\n",
    "            \n",
    "\n",
    "        avg_val_loss = np.mean(val_losses)\n",
    "        avg_val_accuracy = np.mean(val_accuracies)\n",
    "        \n",
    "        print('\\rValidation | Average Accuracy: {:.4f}% Loss: {:.6f}'.format(\n",
    "            avg_val_accuracy * 100,\n",
    "            avg_val_loss), \n",
    "        end=\" \" * 30 + \"\\n\")\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            saver.save(sess, checkpoint_path)\n",
    "            best_val_loss = avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./capsnet_mnist_save\n",
      "Evaluation | Accuracy: 90.8973% Loss: 0.113210                       \n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "\n",
    "test_iterations = len(X_test) // batch_size\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    \n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    \n",
    "    for iteration, (X_batch, y_batch) in enumerate(batch(X_test, y_test, batch_size)):\n",
    "        \n",
    "        test_loss, test_accuracy = sess.run(\n",
    "            [loss, accuracy],\n",
    "            feed_dict={\n",
    "                X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                y: y_batch.reshape([-1]),\n",
    "            },\n",
    "        )\n",
    "        \n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        \n",
    "        print(\"\\rEvaluation | Iteration {}/{} ({:.1f}%)\".format(\n",
    "            iteration + 1, \n",
    "            test_iterations, \n",
    "            (iteration + 1) * 100/test_iterations),\n",
    "             end=\" \" * 30\n",
    "        )\n",
    "        \n",
    "    avg_test_loss = np.mean(test_losses)\n",
    "    avg_test_accuracy = np.mean(test_accuracies)\n",
    "    \n",
    "    print(\"\\rEvaluation | Accuracy: {:.4f}% Loss: {:.6f}\".format(avg_test_accuracy * 100, avg_test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./capsnet_mnist_save\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "\n",
    "n_samples = 2\n",
    "\n",
    "sample_images = X_train[:n_samples].reshape([-1, 28, 28, 1])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    \n",
    "    digitCaps_output, reconstructions_output, predictions_output = sess.run(\n",
    "        [digitCaps, reconstructions, predictions],\n",
    "        feed_dict={\n",
    "            X: sample_images,\n",
    "            y: np.array([], dtype=np.int64) # will not be used\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x216 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x216 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_images = sample_images.reshape([-1, 28, 28])\n",
    "reconstructions_output = reconstructions_output.reshape([-1, 28, 28])\n",
    "\n",
    "plt.figure(figsize=(n_samples * 2, 3))\n",
    "for index in range(n_samples):\n",
    "    plt.subplot(1, n_samples, index + 1)\n",
    "    plt.imshow(sample_images[index], cmap=\"binary\")\n",
    "    plt.title(\"Label:\" + str(y_test[index]))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(n_samples * 2, 3))\n",
    "for index in range(n_samples):\n",
    "    plt.subplot(1, n_samples, index + 1)\n",
    "    plt.imshow(reconstructions_output[index], cmap=\"binary\")\n",
    "    plt.title(\"Predicted:\" + str(predictions_output[index]))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bachelor-Thesis",
   "language": "python",
   "name": "bachelor-thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
